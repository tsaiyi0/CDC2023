---
title: "Diabetes Model"
author: "Elena Tsai"
date: "2023-10-01"
output: html_document
---

```{r}
library(readr)
library(dplyr)
library(nnet)
library(caret)
library(MASS)
library(car)
library(lmtest)
```

```{r}
diabetes <- read.csv("diabetic_data.csv")
#multinomial logistic regression is used to model nominal outcome variables, in this case we are trying to predict readmission categories (No, >30 days, <30 days)

```

```{r}
#Data Preprocessing/Feature Selection
#removed weight, payer code and medical specialty because they had over half of entries missing, removed ID columns, removed specific medication columns because of multicollinearity/redundancy with the diabetesMed column, removed diagnoses 1, 2 and 3 to avoid multicollinearity with number_diagnoses + simplification
diabetes <- subset(diabetes, select = -c(1,2,6,11,12,19:21, 25:47 ))
```

```{r}
#converted variables into factor-type variables so they can be categorical
diabetes <- diabetes %>%
  mutate_at(vars(1:6, 15:19), as.factor)
```

```{r}
#split into training and testing sets for cross validation
index <- createDataPartition(diabetes$readmitted, p = .80, list = FALSE)
train <- diabetes[index,]
test <- diabetes[-index,]
```


```{r}
#BUILDING THE MODEL
#assigning reference level as readmission = 'NO' b/c using multinom function from nnet 
diabetes$readmitted <- relevel(diabetes$readmitted, ref = "NO")
multinom_mod <- multinom(readmitted~., data = diabetes, maxit = 1000)
```

```{r}
#finds odds ratio for each predictor in reference to the reference level. Example: if age is in range [30-40] the odds are 3.845006 times that you will be readmitted in less than 30 days then not readmitted. 
exp(coef(multinom_mod))
```

```{r}
# Predicting the values for train dataset
train$PredictedClass <- predict(multinom_mod, newdata = train, "class")

# Building classification table, columns = predicted, rows = actual
tab <- table(train$readmitted, train$PredictedClass)

# Extract True Positives (TP), True Negatives (TN), and Total Predictions
TP_total <- sum(diag(tab))
TN_total <- sum(tab) - TP_total

# Calculate Accuracy
accuracy_total <- (TP_total + TN_total) / sum(tab)

# Print Accuracy
cat("Accuracy:", round(accuracy_total * 100, 2), "%\n")
 
#Precision
#for class no
TP_NO <- tab[1, 1]
FP_NO <- sum(tab[2:3, 1])
precision_NO <- TP_NO / (TP_NO + FP_NO)

cat("Precision (Class NO):", round(precision_NO * 100, 2), "%\n")
#for class <30
TP_less30 <- tab[2, 2]
FP_less30 <- sum(tab[c(1, 3), 2])
precision_less30 <- TP_less30 / (TP_less30 + FP_less30)

cat("Precision (Class <30):", round(precision_less30 * 100, 2), "%\n")
#for class >30
TP_greater30 <- tab[3, 3]
FP_greater30 <- sum(tab[1:2, 3])
precision_greater30 <- TP_greater30 / (TP_greater30 + FP_greater30)

cat("Precision (Class >30):", round(precision_greater30 * 100, 2), "%\n")

```
```{r}
# Predicting the values for train dataset
test$PredictedClass <- predict(multinom_mod, newdata = test, "class")

# Building classification table, columns = predicted, rows = actual
tab_test <- table(test$readmitted, test$PredictedClass)

# Extract True Positives (TP), True Negatives (TN), and Total Predictions
TP_total_test <- sum(diag(tab_test))
TN_total_test <- sum(tab_test) - TP_total_test

# Calculate Accuracy
accuracy_total_test <- (TP_total_test + TN_total_test) / sum(tab_test)

# Print Accuracy
cat("Accuracy:", round(accuracy_total_test * 100, 2), "%\n")
 
#Precision
#for class no
TP_NO_test <- tab_test[1, 1]
FP_NO_test <- sum(tab_test[2:3, 1])
precision_NO_test <- TP_NO_test / (TP_NO_test + FP_NO_test)

cat("Precision (Class NO):", round(precision_NO_test * 100, 2), "%\n")
#for class <30
TP_less30_test <- tab_test[2, 2]
FP_less30_test <- sum(tab_test[c(1, 3), 2])
precision_less30_test <- TP_less30_test / (TP_less30_test + FP_less30_test)

cat("Precision (Class <30):", round(precision_less30_test * 100, 2), "%\n")
#for class >30
TP_greater30_test <- tab_test[3, 3]
FP_greater30_test <- sum(tab_test[1:2, 3])
precision_greater30_test <- TP_greater30_test / (TP_greater30_test + FP_greater30_test)

cat("Precision (Class >30):", round(precision_greater30_test * 100, 2), "%\n")
```
```{r}
# Get the coefficients from the multinomial logistic regression model
coefficients <- coef(multinom_mod)

# Calculate the absolute values of coefficients for each predictor
absolute_coefficients <- abs(coefficients)

# Find and print the top 5 most influential predictor variables for each class
top_5_influential <- apply(absolute_coefficients, 1, function(x) {
  top_5_indices <- tail(order(x, decreasing = TRUE), 5)
  top_5_predictors <- colnames(absolute_coefficients)[top_5_indices]
  paste(top_5_predictors, collapse = ", ")
})

# Create a data frame with the results
result_df <- data.frame(
  Class = rownames(absolute_coefficients),
  Top_Predictors = top_5_influential
)

# Print the top 5 most influential predictor variables for each class
print(result_df)


```

```{r}
abs(coef(multinom_mod))
```


```{r}
z <- summary(multinom_mod)$coefficients/summary(multinom_mod)$standard.errors
# 2-tailed Wald z tests to test significance of coefficients
p <- (1 - pnorm(abs(z), 0, 1)) * 2
# Create a data frame with coefficients, standard errors, z-scores, and p-values
results_table <- data.frame(
  Coefficients = summary(multinom_mod)$coefficients,
  Standard_Errors = summary(multinom_mod)$standard.errors,
  Z_Scores = z,
  P_Values = p
)

# Print the results table
print(results_table)
```
```{r}
results_table$
```

```{r}
null_model <- multinom(readmitted ~ 1, data = diabetes)
lrt_result <- lrtest(multinom_mod, null_model)
lrt_result

#he likelihood ratio test results suggest that Model 1, which includes predictor variables, provides a significantly better fit to the data than Model 2 (the null model) based on the the associated p-value. 
```


